{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec: How To Implement word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Pre-trained Embeddings\n",
    "\n",
    "Some other options:\n",
    "- `glove-twitter-{25/50/100/200}`\n",
    "- `glove-wiki-gigaword-{50/200/300}`\n",
    "- `word2vec-google-news-300`\n",
    "- `word2vec-ruscorpora-news-300`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\d022785\\appdata\\roaming\\python\\python312\\site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\d022785\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\d022785\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim) (1.11.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\d022785\\appdata\\roaming\\python\\python312\\site-packages (from gensim) (6.4.0)\n"
     ]
    }
   ],
   "source": [
    "# Install gensim\n",
    "!pip install -U --user gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load pretrained word vectors using gensim\n",
    "import gensim.downloader as api\n",
    "\n",
    "wiki_embeddings = api.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.32307 , -0.87616 ,  0.21977 ,  0.25268 ,  0.22976 ,  0.7388  ,\n",
       "       -0.37954 , -0.35307 , -0.84369 , -1.1113  , -0.30266 ,  0.33178 ,\n",
       "       -0.25113 ,  0.30448 , -0.077491, -0.89815 ,  0.092496, -1.1407  ,\n",
       "       -0.58324 ,  0.66869 , -0.23122 , -0.95855 ,  0.28262 , -0.078848,\n",
       "        0.75315 ,  0.26584 ,  0.3422  , -0.33949 ,  0.95608 ,  0.065641,\n",
       "        0.45747 ,  0.39835 ,  0.57965 ,  0.39267 , -0.21851 ,  0.58795 ,\n",
       "       -0.55999 ,  0.63368 , -0.043983, -0.68731 , -0.37841 ,  0.38026 ,\n",
       "        0.61641 , -0.88269 , -0.12346 , -0.37928 , -0.38318 ,  0.23868 ,\n",
       "        0.6685  , -0.43321 , -0.11065 ,  0.081723,  1.1569  ,  0.78958 ,\n",
       "       -0.21223 , -2.3211  , -0.67806 ,  0.44561 ,  0.65707 ,  0.1045  ,\n",
       "        0.46217 ,  0.19912 ,  0.25802 ,  0.057194,  0.53443 , -0.43133 ,\n",
       "       -0.34311 ,  0.59789 , -0.58417 ,  0.068995,  0.23944 , -0.85181 ,\n",
       "        0.30379 , -0.34177 , -0.25746 , -0.031101, -0.16285 ,  0.45169 ,\n",
       "       -0.91627 ,  0.64521 ,  0.73281 , -0.22752 ,  0.30226 ,  0.044801,\n",
       "       -0.83741 ,  0.55006 , -0.52506 , -1.7357  ,  0.4751  , -0.70487 ,\n",
       "        0.056939, -0.7132  ,  0.089623,  0.41394 , -1.3363  , -0.61915 ,\n",
       "       -0.33089 , -0.52881 ,  0.16483 , -0.98878 ], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the word vector for \"king\"\n",
    "wiki_embeddings['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.50045 , -0.70826 ,  0.55388 ,  0.673   ,  0.22486 ,  0.60281 ,\n",
       "       -0.26194 ,  0.73872 , -0.65383 , -0.21606 , -0.33806 ,  0.24498 ,\n",
       "       -0.51497 ,  0.8568  , -0.37199 , -0.58824 ,  0.30637 , -0.30668 ,\n",
       "       -0.2187  ,  0.78369 , -0.61944 , -0.54925 ,  0.43067 , -0.027348,\n",
       "        0.97574 ,  0.46169 ,  0.11486 , -0.99842 ,  1.0661  , -0.20819 ,\n",
       "        0.53158 ,  0.40922 ,  1.0406  ,  0.24943 ,  0.18709 ,  0.41528 ,\n",
       "       -0.95408 ,  0.36822 , -0.37948 , -0.6802  , -0.14578 , -0.20113 ,\n",
       "        0.17113 , -0.55705 ,  0.7191  ,  0.070014, -0.23637 ,  0.49534 ,\n",
       "        1.1576  , -0.05078 ,  0.25731 , -0.091052,  1.2663  ,  1.1047  ,\n",
       "       -0.51584 , -2.0033  , -0.64821 ,  0.16417 ,  0.32935 ,  0.048484,\n",
       "        0.18997 ,  0.66116 ,  0.080882,  0.3364  ,  0.22758 ,  0.1462  ,\n",
       "       -0.51005 ,  0.63777 ,  0.47299 , -0.3282  ,  0.083899, -0.78547 ,\n",
       "        0.099148,  0.039176,  0.27893 ,  0.11747 ,  0.57862 ,  0.043639,\n",
       "       -0.15965 , -0.35304 , -0.048965, -0.32461 ,  1.4981  ,  0.58138 ,\n",
       "       -1.132   , -0.60673 , -0.37505 , -1.1813  ,  0.80117 , -0.50014 ,\n",
       "       -0.16574 , -0.70584 ,  0.43012 ,  0.51051 , -0.8033  , -0.66572 ,\n",
       "       -0.63717 , -0.36032 ,  0.13347 , -0.56075 ], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_embeddings['queen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.7293e-01,  3.8503e-01,  7.1086e-01, -6.5911e-01, -1.0128e-03,\n",
       "        9.2715e-01,  2.7615e-01, -5.6203e-02, -2.4294e-01,  2.4632e-01,\n",
       "       -1.8449e-01,  3.1398e-01,  4.8983e-01,  9.2560e-02,  3.2958e-01,\n",
       "        1.5056e-01,  5.7317e-01, -1.8529e-01, -5.2277e-01,  4.6191e-01,\n",
       "        9.2038e-01,  3.1001e-02, -1.6246e-01, -4.0567e-01,  7.8621e-01,\n",
       "        5.7722e-01, -5.3501e-01, -6.8228e-01,  1.6987e-01,  3.6310e-01,\n",
       "       -7.1773e-02,  4.7233e-01,  2.7806e-02, -1.4951e-01,  1.7543e-01,\n",
       "       -3.7573e-01, -7.8517e-01,  5.8171e-01,  8.6859e-01,  3.1445e-02,\n",
       "       -4.5897e-01, -4.0917e-02,  9.5897e-01, -1.6975e-01,  1.3045e-01,\n",
       "        2.7434e-01, -6.9485e-02,  2.2402e-02,  2.4977e-01, -2.1536e-01,\n",
       "       -3.2406e-01, -3.9867e-01,  6.8613e-01,  1.7923e+00, -3.7848e-01,\n",
       "       -2.2477e+00, -7.7025e-01,  4.6582e-01,  1.2411e+00,  5.7756e-01,\n",
       "        4.1151e-01,  8.4328e-01, -5.4259e-01, -1.6715e-01,  7.3927e-01,\n",
       "       -9.3477e-02,  9.0278e-01,  5.0889e-01, -5.0031e-01,  2.6451e-01,\n",
       "        1.5443e-01, -2.9432e-01,  1.0906e-01, -2.6667e-01,  3.5438e-01,\n",
       "        4.9079e-02,  1.8018e-01, -5.8590e-01, -5.5542e-01, -2.8987e-01,\n",
       "        7.4278e-01,  3.4530e-01, -2.8757e-02, -2.2646e-01, -1.3113e+00,\n",
       "       -5.7190e-01, -5.2306e-01, -1.2670e-01, -9.8678e-02, -5.3463e-01,\n",
       "        2.8607e-01, -3.7501e-01,  4.5742e-01,  4.5975e-02, -2.4675e-01,\n",
       "        4.5656e-02, -3.8302e-01, -9.3711e-01,  3.9138e-02, -5.3911e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_embeddings['man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.59368 ,  0.44825 ,  0.5932  ,  0.074134,  0.11141 ,  1.2793  ,\n",
       "        0.16656 ,  0.2407  ,  0.39045 ,  0.32766 , -0.75034 ,  0.35007 ,\n",
       "        0.76057 ,  0.38067 ,  0.17517 ,  0.031791,  0.46849 , -0.21653 ,\n",
       "       -0.46282 ,  0.39967 ,  0.16623 , -0.011477,  0.044059,  0.30325 ,\n",
       "        0.6153  ,  0.47047 , -0.44036 , -1.5963  ,  0.18433 ,  0.23193 ,\n",
       "        0.20452 ,  0.51617 ,  0.65734 , -0.3452  ,  0.23446 , -0.62004 ,\n",
       "       -0.68741 ,  0.28575 ,  1.0605  ,  0.46916 , -0.85149 ,  0.10154 ,\n",
       "        0.21426 , -0.20587 ,  0.23636 ,  0.21321 , -0.21287 ,  0.12107 ,\n",
       "        0.18766 , -0.23282 , -0.25499 , -0.39631 ,  0.84379 ,  1.6801  ,\n",
       "       -0.40941 , -1.9976  , -0.69868 ,  0.21732 ,  1.2197  ,  0.55126 ,\n",
       "        0.44095 ,  0.72588 , -0.092053, -0.022406,  0.72039 ,  0.1076  ,\n",
       "        0.84116 ,  0.30312 , -0.42544 ,  0.056362,  0.13109 , -0.071181,\n",
       "       -0.10579 ,  0.56677 ,  0.54547 ,  0.84113 ,  0.14861 , -0.62628 ,\n",
       "       -0.68391 , -1.0831  , -0.088385,  0.32167 ,  0.47794 ,  0.091868,\n",
       "       -1.2559  , -1.2268  ,  0.085401,  0.36833 ,  0.081566, -0.76611 ,\n",
       "        0.87751 , -0.22008 ,  0.82401 , -0.092207, -0.45941 ,  0.46571 ,\n",
       "       -0.56018 , -0.54648 ,  0.15162 , -0.30754 ], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_embeddings['woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.39813006, -0.10468006, -0.45176995,  0.31292403,  0.11732282,\n",
       "        0.48814   , -0.22718996, -0.79488695,  0.44353002, -0.81390005,\n",
       "       -0.53045   ,  0.12288997,  0.53458   , -0.26421005,  0.140089  ,\n",
       "       -0.428679  , -0.31855398, -0.86526   , -0.30459   , -0.17723995,\n",
       "       -0.36593002, -0.45177794,  0.05846903,  0.65742   , -0.39350003,\n",
       "       -0.30260003,  0.32199   , -0.25509   , -0.09556001,  0.14266099,\n",
       "        0.20218301,  0.03297001,  0.16858399, -0.05245   , -0.34657001,\n",
       "       -0.07163998,  0.49185002, -0.03049999,  0.52740705,  0.43060496,\n",
       "       -0.6251501 ,  0.72384703, -0.29943   , -0.36176002, -0.73665   ,\n",
       "       -0.510424  , -0.29019496, -0.157992  , -0.55121005, -0.39989   ,\n",
       "       -0.29889002,  0.17513499,  0.04826009, -0.42732   ,  0.27267998,\n",
       "       -0.06770015,  0.04172003,  0.03293997,  0.30632   ,  0.02971598,\n",
       "        0.30164003, -0.57944   ,  0.62767506, -0.134462  ,  0.28797007,\n",
       "       -0.37645298,  0.10531998, -0.24564996, -0.98229   ,  0.18904701,\n",
       "        0.13220099,  0.15679902, -0.01020798,  0.45249403, -0.34530002,\n",
       "        0.64348   , -0.77304006,  0.367671  , -0.88511   ,  0.2050201 ,\n",
       "       -0.04939001,  0.07345998, -0.68914306, -0.21825099,  0.34999   ,\n",
       "        0.50188994,  0.45845103, -0.05936992, -0.14582598, -0.43620998,\n",
       "        0.81411904,  0.14757001,  0.02609304, -0.234752  , -0.74565995,\n",
       "        0.466624  ,  0.12912005,  0.22213998,  0.14384198, -0.19646001],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_embeddings['king'] - wiki_embeddings['man'] + wiki_embeddings['woman'] - wiki_embeddings['queen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prince', 0.7682328820228577),\n",
       " ('queen', 0.7507690787315369),\n",
       " ('son', 0.7020888328552246),\n",
       " ('brother', 0.6985775232315063),\n",
       " ('monarch', 0.6977890729904175),\n",
       " ('throne', 0.6919989585876465),\n",
       " ('kingdom', 0.6811409592628479),\n",
       " ('father', 0.6802029013633728),\n",
       " ('emperor', 0.6712858080863953),\n",
       " ('ii', 0.6676074266433716)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_embeddings.most_similar(['king'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prince', 0.7682328820228577),\n",
       " ('queen', 0.7507690787315369),\n",
       " ('son', 0.7020888328552246),\n",
       " ('brother', 0.6985775232315063),\n",
       " ('monarch', 0.6977890729904175),\n",
       " ('throne', 0.6919989585876465),\n",
       " ('kingdom', 0.6811409592628479),\n",
       " ('father', 0.6802029013633728),\n",
       " ('emperor', 0.6712858080863953),\n",
       " ('ii', 0.6676074266433716)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_embeddings.similar_by_word('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7507691"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity = wiki_embeddings.similarity('king', 'queen')\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7123123"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity = wiki_embeddings.similarity('man', 'being')\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the words most similar to king based on the trained word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Our Own Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                  text  \n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...  \n",
       "1                                                                        Ok lar... Joking wif u oni...  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
       "3                                                    U dun say so early hor... U c already then say...  \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data and clean up column names\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "messages = pd.read_csv('../../../data/spam.csv', encoding='latin-1')\n",
    "messages = messages.drop(labels = [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis = 1)\n",
    "messages.columns = [\"label\", \"text\"]\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, only, in, bugis, great, world, la, buffet, cine, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>[free, entry, in, wkly, comp, to, win, fa, cup, final, tkts, st, may, text, fa, to, to, receive,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[dun, say, so, early, hor, already, then, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>[nah, don, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                  text  \\\n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
       "1                                                                        Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "3                                                    U dun say so early hor... U c already then say...   \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "                                                                                            text_clean  \n",
       "0  [go, until, jurong, point, crazy, available, only, in, bugis, great, world, la, buffet, cine, th...  \n",
       "1                                                                          [ok, lar, joking, wif, oni]  \n",
       "2  [free, entry, in, wkly, comp, to, win, fa, cup, final, tkts, st, may, text, fa, to, to, receive,...  \n",
       "3                                                       [dun, say, so, early, hor, already, then, say]  \n",
       "4                                [nah, don, think, he, goes, to, usf, he, lives, around, here, though]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean data using the built in cleaner in gensim\n",
    "messages['text_clean'] = messages['text'].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(messages['text_clean'],\n",
    "                                                    messages['label'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the word2vec model\n",
    "w2v_model = gensim.models.Word2Vec(X_train, vector_size=100, window=5 , min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03682343,  0.04675885,  0.00758498,  0.00618662,  0.0034996 ,\n",
       "       -0.1064664 ,  0.01525266,  0.1313823 , -0.05436319, -0.03731774,\n",
       "       -0.03200949, -0.09451208, -0.014351  ,  0.01625956,  0.02455207,\n",
       "       -0.04669506,  0.0121477 , -0.070802  ,  0.00966692, -0.1258004 ,\n",
       "        0.03315085,  0.01487759,  0.0502426 , -0.04070464, -0.02188593,\n",
       "       -0.0026664 , -0.0455755 , -0.02635047, -0.04419878,  0.00414022,\n",
       "        0.04966126, -0.00922324,  0.02061136, -0.05829772, -0.02516592,\n",
       "        0.07297933,  0.01677565, -0.05128374, -0.03531425, -0.09387387,\n",
       "       -0.00786178, -0.04812487, -0.03596288,  0.00846946,  0.05443931,\n",
       "       -0.01757075, -0.07366505, -0.01299695,  0.04803235,  0.04263426,\n",
       "        0.03075044, -0.05490296,  0.00075537,  0.02433788, -0.01246264,\n",
       "        0.03127469,  0.05374309, -0.04379884, -0.05687412,  0.03632596,\n",
       "        0.01982387,  0.01302365, -0.01640747, -0.00201469, -0.06665744,\n",
       "        0.06973889,  0.01187222,  0.02721813, -0.07929934,  0.06993265,\n",
       "       -0.02861409,  0.02619795,  0.06514221, -0.01124717,  0.05836144,\n",
       "        0.02547751,  0.00582539, -0.0152132 , -0.05581144, -0.00285891,\n",
       "       -0.03602377,  0.00955988, -0.08175799,  0.08734474, -0.04075649,\n",
       "       -0.01491743,  0.02733236,  0.03947752,  0.08205634,  0.02570593,\n",
       "        0.09682487,  0.04976436, -0.00642608,  0.0158307 ,  0.09077947,\n",
       "        0.06041822,  0.00971076, -0.05303699,  0.01941049,  0.01589843],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the word vector for \"king\" base on our trained model\n",
    "w2v_model.wv['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('person', 0.992994487285614),\n",
       " ('then', 0.9928323030471802),\n",
       " ('tmr', 0.9926416277885437),\n",
       " ('thats', 0.992638349533081),\n",
       " ('oso', 0.9926360249519348),\n",
       " ('really', 0.9926297664642334),\n",
       " ('lunch', 0.9926167130470276),\n",
       " ('ll', 0.9926100373268127),\n",
       " ('use', 0.992599606513977),\n",
       " ('nyt', 0.9925970435142517)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the most similar words to \"king\" based on word vectors from our trained model\n",
    "w2v_model.wv.most_similar('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('person', 0.992994487285614),\n",
       " ('then', 0.9928323030471802),\n",
       " ('tmr', 0.9926416277885437),\n",
       " ('thats', 0.992638349533081),\n",
       " ('oso', 0.9926360249519348),\n",
       " ('really', 0.9926297664642334),\n",
       " ('lunch', 0.9926167130470276),\n",
       " ('ll', 0.9926100373268127),\n",
       " ('use', 0.992599606513977),\n",
       " ('nyt', 0.9925970435142517)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similar_by_word('king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 1.0),\n",
       " ('person', 0.9929945468902588),\n",
       " ('then', 0.9928323030471802),\n",
       " ('tmr', 0.9926416277885437),\n",
       " ('thats', 0.992638349533081),\n",
       " ('oso', 0.9926360249519348),\n",
       " ('really', 0.9926297664642334),\n",
       " ('lunch', 0.9926167130470276),\n",
       " ('ll', 0.9926100373268127),\n",
       " ('use', 0.992599606513977)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similar_by_vector(w2v_model.wv['king'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
