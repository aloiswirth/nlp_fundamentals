{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doc2vec: How To Implement doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Our Own Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data, clean it, and then split into train and test sets\n",
    "import gensim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "messages = pd.read_csv('../../../data/spam.csv', encoding='latin-1')\n",
    "messages = messages.drop(labels = [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis = 1)\n",
    "messages.columns = [\"label\", \"text\"]\n",
    "messages['text_clean'] = messages['text'].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(messages['text_clean'],\n",
    "                                                    messages['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tagged document objects to prepare to train the model\n",
    "tagged_docs = [gensim.models.doc2vec.TaggedDocument(v, [i]) for i, v in enumerate(X_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['no', 'in', 'the', 'same', 'boat', 'still', 'here', 'at', 'my', 'moms', 'check', 'me', 'out', 'on', 'yo', 'half', 'naked'], tags=[0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at what a tagged document looks like\n",
    "tagged_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a basic doc2vec model\n",
    "d2v_model = gensim.models.Doc2Vec(tagged_docs,\n",
    "                                  vector_size=100,\n",
    "                                  window=5,\n",
    "                                  min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.07916268e-02, -2.55744322e-03,  4.33045160e-03,  7.02752452e-03,\n",
       "        1.32111087e-03, -1.99317746e-02,  3.10294633e-03,  2.55917963e-02,\n",
       "       -9.92034562e-03, -2.41003837e-03, -1.61863994e-02, -3.14948037e-02,\n",
       "       -3.51460208e-03,  6.84878463e-03,  3.08868848e-03, -8.30354076e-03,\n",
       "       -1.23882620e-03, -2.07861215e-02,  7.59332674e-03, -2.31476687e-02,\n",
       "        2.80159991e-03,  2.95096938e-03,  1.26693761e-02,  6.11723261e-03,\n",
       "       -1.32910197e-03, -5.69444243e-03, -1.68613400e-02, -2.51554069e-03,\n",
       "       -7.66403507e-03, -3.06299562e-03,  6.43154560e-03,  1.31174427e-04,\n",
       "        8.74533318e-03, -8.14582279e-04, -1.78447030e-02,  7.03175971e-03,\n",
       "        7.22076977e-03, -2.10495200e-02, -1.85112078e-02, -1.95066109e-02,\n",
       "        1.45747563e-05, -1.76859144e-02, -8.77946895e-03, -4.22434974e-03,\n",
       "        7.11523322e-03, -7.08890427e-03, -6.31457800e-03,  2.39501009e-03,\n",
       "        4.44851164e-03,  1.23836370e-02,  6.93360576e-03, -1.17320977e-02,\n",
       "        9.63179627e-04, -2.71024695e-03, -4.57956316e-03,  5.27316937e-03,\n",
       "        1.36438031e-02, -4.17670375e-03, -1.28785018e-02,  1.14141703e-02,\n",
       "       -1.83128717e-03, -4.60955035e-03,  1.20736770e-02, -6.29982632e-03,\n",
       "       -1.41538987e-02,  1.04360115e-02,  4.65018675e-03,  1.88240558e-02,\n",
       "       -1.17444061e-02,  1.64825097e-02,  2.65336968e-03,  1.32071339e-02,\n",
       "        1.57645307e-02, -9.72327683e-03,  1.30581148e-02, -2.59300647e-03,\n",
       "        5.54069318e-03, -1.00055235e-02, -9.27097723e-03, -1.27091480e-03,\n",
       "       -2.27656420e-02, -4.90364665e-03, -1.59061458e-02,  1.96558330e-02,\n",
       "       -6.42968761e-03, -3.15434020e-03, -3.54703958e-03,  6.44525792e-03,\n",
       "        2.61607338e-02,  8.46771989e-03,  2.41628382e-02,  1.45873995e-02,\n",
       "        5.26939379e-03,  7.35639734e-03,  2.18982715e-02,  1.45843914e-02,\n",
       "        9.53516643e-03, -1.87070873e-02,  7.68713886e-03, -3.30403447e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What happens if we pass in a single word like we did for word2vec?\n",
    "d2v_model.infer_vector(['this', 'is', 'a', 'huge', 'list', 'of', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01700153,  0.00577108,  0.0101187 ,  0.00490633, -0.00031176,\n",
       "       -0.02831088,  0.00761476,  0.04902763, -0.02448422, -0.01226932,\n",
       "       -0.02015222, -0.04734956, -0.00930245,  0.01006988,  0.00294703,\n",
       "       -0.01775146,  0.01644256, -0.022983  ,  0.00643468, -0.04019548,\n",
       "        0.00051399,  0.00992351,  0.01574207, -0.00346417,  0.00401343,\n",
       "        0.00473351, -0.02822516, -0.00351303, -0.02285006, -0.00376918,\n",
       "        0.02334438,  0.00736679,  0.01160903, -0.00379197, -0.02693884,\n",
       "        0.02561853,  0.0024503 , -0.02500274, -0.01698458, -0.03593631,\n",
       "       -0.00236918, -0.02297402, -0.01352627, -0.00394192,  0.00231925,\n",
       "       -0.01610782, -0.00692643, -0.01140777,  0.00688177,  0.0196486 ,\n",
       "        0.00312065, -0.01585424, -0.00064299, -0.00290738, -0.01947271,\n",
       "        0.00785106,  0.01799404, -0.00966279, -0.02353499,  0.01477516,\n",
       "       -0.00295802, -0.00786071,  0.00681761, -0.00878007, -0.02471401,\n",
       "        0.02451266,  0.00360113,  0.02209847, -0.02125034,  0.03485629,\n",
       "       -0.00618466,  0.01782719,  0.02685902, -0.00045935,  0.02940864,\n",
       "       -0.00321849,  0.00030144, -0.00773119, -0.00883019, -0.00113579,\n",
       "       -0.02621078, -0.00187561, -0.01889096,  0.02639131, -0.01195518,\n",
       "       -0.00604903, -0.005857  ,  0.01193339,  0.02688364,  0.01261129,\n",
       "        0.03236635,  0.02039079,  0.00909877,  0.00730377,  0.03365012,\n",
       "        0.02450771,  0.01294372, -0.02878923,  0.02075936,  0.00331305],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v_model.infer_vector(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00079993, -0.00241487, -0.003925  , -0.00077622,  0.00487272,\n",
       "       -0.00461449, -0.00794001,  0.00196816,  0.00256167, -0.00207712,\n",
       "        0.00389052, -0.0015462 ,  0.00244023,  0.00461275, -0.00154543,\n",
       "        0.00264698,  0.00525391, -0.0001179 , -0.00114382, -0.00311834,\n",
       "        0.00311693, -0.00325406, -0.00234914, -0.00691736, -0.00262643,\n",
       "        0.0018867 ,  0.00836094,  0.00718936,  0.00242413,  0.00249124,\n",
       "       -0.00931214,  0.00028316, -0.00117485, -0.0015381 , -0.00051082,\n",
       "       -0.0057246 , -0.00228752,  0.00489969,  0.0020843 , -0.00081044,\n",
       "        0.0034014 , -0.00524214,  0.00602016,  0.00141408, -0.00834089,\n",
       "       -0.00269645,  0.00258314,  0.00466208, -0.00043998,  0.00442808,\n",
       "        0.00301475, -0.00173231, -0.0065721 , -0.00124466,  0.00094067,\n",
       "        0.00072978,  0.00052168,  0.00407398, -0.0114823 ,  0.00668782,\n",
       "        0.00651658,  0.00268903,  0.00242151,  0.00690527, -0.00234641,\n",
       "        0.00398679,  0.00798854, -0.00370699, -0.00117224,  0.00442532,\n",
       "        0.00467887, -0.00443971, -0.00063281,  0.00781734,  0.00221071,\n",
       "        0.00500185,  0.007094  ,  0.00445481, -0.00296472,  0.00345267,\n",
       "       -0.00240983,  0.000122  ,  0.00618587,  0.00265452, -0.0021859 ,\n",
       "        0.00021943,  0.00482935, -0.00021277, -0.00391559, -0.00473057,\n",
       "        0.00586162, -0.00233925, -0.00369122, -0.00095092, -0.00056093,\n",
       "        0.00324085,  0.00587594,  0.00096656, -0.00070719, -0.00448769],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What happens if we pass in a list of words?\n",
    "d2v_model.infer_vector(['i', 'am', 'learning', 'nlp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What About Pre-trained Document Vectors?\n",
    "\n",
    "There are not as many options as there are for word vectors. There also is not an easy API to read these in like there is for `word2vec` so it is more time consuming.\n",
    "\n",
    "Pre-trained vectors from training on Wikipedia and Associated Press News can be found [here](https://github.com/jhlau/doc2vec). Feel free to explore on your own!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
